{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask,request,render_template,jsonify\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import joblib\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from moviepy import AudioFileClip\n",
    "from moviepy import VideoFileClip\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=Flask(__name__)\n",
    "app.config['UPLOAD_FOLDER']='uploads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(app.config['UPLOAD_FOLDER'],exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('upload.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and preprocessing for input of image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_and_labels(video_path, frame_count, img_size=(224, 224)):\n",
    "    X_data = []\n",
    "    \n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames < frame_count:\n",
    "        print(f\"Video too short to extract {frame_count} frames.\")\n",
    "        video.release()\n",
    "        return np.array([]), np.array([])\n",
    "    step_size = total_frames // frame_count\n",
    "    for i in range(frame_count):\n",
    "        frame_index = i * step_size\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "        ret, frame = video.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, img_size)\n",
    "            X_data.append(frame)\n",
    "\n",
    "    \n",
    "    frames = []\n",
    "    for frame in X_data:\n",
    "        frame = frame / 255.0\n",
    "        frames.append(frame)\n",
    "    video.release()\n",
    "\n",
    "    return np.array([frames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and preprocessing of input for audio model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(video_path, output_audio_path):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    flag = True\n",
    "    if video_clip.audio is not None:\n",
    "        audio_clip = video_clip.audio\n",
    "        audio_clip.write_audiofile(output_audio_path)\n",
    "        audio_clip.close()\n",
    "        print(\"Audio extracted and saved.\")\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"No audio track found in the video.\")\n",
    "\n",
    "    video_clip.close()\n",
    "    return flag\n",
    "    \n",
    "def extract_features(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    os.remove(audio_path)\n",
    "    features = {    }\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    \n",
    "    selected_mfcc_indices = [3] + list(range(5, 21))\n",
    "    for i in selected_mfcc_indices:\n",
    "        features[f'mfcc{i}'] = np.mean(mfccs[i - 1])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import render_template\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_video():\n",
    "    if 'video' not in request.files:\n",
    "        return render_template('upload.html', error=\"No video is found\")\n",
    "    \n",
    "    video = request.files['video']\n",
    "    if video.filename == '':\n",
    "        return render_template('upload.html', error=\"No selected video\")\n",
    "    \n",
    "    if video:\n",
    "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], video.filename)\n",
    "        video.save(filepath)\n",
    "        data = extract_frames_and_labels(filepath, 32)\n",
    "        model_image = load_model(\"FramesModel.h5\")\n",
    "        prediction_video = model_image.predict(data)\n",
    "        audio_path = \"extracted_audio.wav\"\n",
    "        flag = extract_audio(filepath, audio_path)\n",
    "\n",
    "        if flag:\n",
    "            features = extract_features(audio_path)\n",
    "            columns = list(features.keys())\n",
    "            values = list(features.values())\n",
    "            audio_data = pd.DataFrame([values], columns=columns)\n",
    "            pt=PowerTransformer()\n",
    "            audio_data['mfcc3']=pt.fit_transform(audio_data[['mfcc3']])\n",
    "            scaler=joblib.load('Scaler.pkl')\n",
    "            audio_data.iloc[:, :] = scaler.transform(audio_data)\n",
    "            audio_model = load_model(\"new_sigmoid.h5\")\n",
    "            prediction_audio = audio_model.predict(audio_data)\n",
    "\n",
    "       \n",
    "        response = {\n",
    "            \"combined_result\": None,\n",
    "            \"final_label\": None\n",
    "        }\n",
    "        if prediction_audio is not None:\n",
    "            result = prediction_video * 0.5 + prediction_audio*0.5\n",
    "            response[\"combined_result\"] = float(result) \n",
    "            response[\"final_label\"] = \"1 (Deepfake)\" if result >0.5 else \"0 (Not Deepfake)\"\n",
    "        else:\n",
    "            result = prediction_video\n",
    "            response[\"combined_result\"] = float(result) \n",
    "            response[\"final_label\"] = \"1 (Deepfake)\" if result >0.5 else \"0 (Not Deepfake)\"\n",
    "            \n",
    "        print(prediction_video)\n",
    "        print(prediction_audio)\n",
    "        return render_template('upload.html', response=response)\n",
    "\n",
    "    return render_template('upload.html', error=\"Unexpected error occurred\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [17/Jan/2025 22:56:06] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "MoviePy - Writing audio in extracted_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extracted and saved.\n",
      "1/1 [==============================] - 0s 114ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaa\\AppData\\Local\\Temp\\ipykernel_8620\\80476574.py:46: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  response[\"combined_result\"] = float(result)  # Cast to native float\n",
      "127.0.0.1 - - [17/Jan/2025 22:56:32] \"\u001b[37mPOST /upload HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2734]]\n",
      "[[0.20858487]]\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "MoviePy - Writing audio in extracted_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extracted and saved.\n",
      "1/1 [==============================] - 0s 144ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaa\\AppData\\Local\\Temp\\ipykernel_8620\\80476574.py:46: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  response[\"combined_result\"] = float(result)  # Cast to native float\n",
      "127.0.0.1 - - [17/Jan/2025 22:57:52] \"\u001b[37mPOST /upload HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1632]]\n",
      "[[0.34082747]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
